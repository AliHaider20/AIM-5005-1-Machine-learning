{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49d447fa",
   "metadata": {},
   "source": [
    "# 1. Implement Boosting method (50 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d33a6065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from scipy.io import loadmat\n",
    "from tqdm import tqdm\n",
    "from pandas import DataFrame\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0640713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost:\n",
    "    def __init__(self, n_estimators,model):\n",
    "        '''\n",
    "        n_estimators - number of estimators\n",
    "        estimators - list that contains all estimators of our model\n",
    "        estimator_weights-hold the weights assigned to each weak classifier in the final model.\n",
    "        self.estimator_errors - hold the errors made by each weak classifier during training\n",
    "        '''\n",
    "        self.n_estimators = n_estimators\n",
    "        self.estimators = []\n",
    "        self.estimator_weights = np.zeros(n_estimators)\n",
    "        self.estimator_errors = np.zeros(n_estimators)\n",
    "        self.model=model\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Initialize sample weights\n",
    "        sample_weights = np.full(X.shape[0], 1/X.shape[0])\n",
    "\n",
    "        for i in tqdm(range(self.n_estimators)):\n",
    "            # Train weak classifier on weighted data\n",
    "          estimator = self.model\n",
    "\n",
    "          estimator.fit(X, y, sample_weight=sample_weights)\n",
    "\n",
    "          # Compute error of weak classifier\n",
    "          y_pred = estimator.predict(X)\n",
    "          incorrect = y_pred != y\n",
    "          estimator_error = np.sum(sample_weights[incorrect])\n",
    "\n",
    "          # Compute weight of weak classifier\n",
    "          if estimator_error == 0:\n",
    "            estimator_weight = 1\n",
    "          elif estimator_error == 1:\n",
    "            estimator_weight = 0\n",
    "          else:\n",
    "            estimator_weight = np.log((1 - estimator_error) / estimator_error)\n",
    "\n",
    "           # Update sample weights\n",
    "          sample_weights *= np.exp((estimator_weight * incorrect) * 1e-3)\n",
    "          sample_weights /= np.sum(sample_weights)\n",
    "\n",
    "           # Save weak classifier and its weight\n",
    "          self.estimators.append(estimator)\n",
    "          self.estimator_weights[i] = estimator_weight\n",
    "          self.estimator_errors[i] = estimator_error\n",
    "\n",
    "\n",
    "    \n",
    "    def predict(self, X,num_classes):\n",
    "        n_classes = num_classes\n",
    "        pred = np.zeros((X.shape[0], n_classes))\n",
    "        for i, estimator in enumerate(self.estimators):\n",
    "            pred += self.estimator_weights[i] * estimator.predict_proba(X)\n",
    "        return np.argmax(pred, axis=1)+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fb48d9",
   "metadata": {},
   "source": [
    "# 2. Load train and test mat files, perform Boosting with Decision Tree and report acuracy on the test dataset (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "64d488cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=loadmat('train.mat')\n",
    "X_train =train_data['features']\n",
    "y_train=train_data['labels'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "074d498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=loadmat('test.mat')\n",
    "X_test =test_data['features']\n",
    "y_test=test_data['labels'].flatten()\n",
    "accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b9c7196c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:22<00:00,  1.47s/it]\n"
     ]
    }
   ],
   "source": [
    "DT = DecisionTreeClassifier(max_depth=10, random_state=20)\n",
    "adaboost = AdaBoost(n_estimators=15, model=DT)\n",
    "adaboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "49ceef08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from this model is 0.918580375782881\n"
     ]
    }
   ],
   "source": [
    "y_pred=adaboost.predict(X_test, num_classes=10)\n",
    "accuracies.append((y_pred == y_test).sum()/len(y_pred))\n",
    "print(f'Accuracy from this model is {accuracies[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35295cc",
   "metadata": {},
   "source": [
    "# 3. Compare results with single decision tree, SVM and KNN model (20 points)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5377fa30",
   "metadata": {},
   "source": [
    "Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e792fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from this model is 0.9196242171189979\n"
     ]
    }
   ],
   "source": [
    "DT.fit(X_train,y_train)\n",
    "y_pred=DT.predict(X_test)\n",
    "accuracies.append((y_pred == y_test).sum()/len(y_pred))\n",
    "print(f'Accuracy from this model is {accuracies[-1]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f599ddb9",
   "metadata": {},
   "source": [
    "Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cc084e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from this model is 0.9530271398747391\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train,y_train)\n",
    "y_pred=svc.predict(X_test)\n",
    "accuracies.append((y_pred == y_test).sum()/len(y_pred))\n",
    "print(f'Accuracy from this model is {accuracies[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d742667e",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "49db9dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from this model is 0.9551148225469729\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred=knn.predict(X_test)\n",
    "accuracies.append((y_pred == y_test).sum()/len(y_pred))\n",
    "print(f'Accuracy from this model is {accuracies[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8e13366b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.955115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.953027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.919624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost (DT)</th>\n",
       "      <td>0.918580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Accuracy\n",
       "KNN            0.955115\n",
       "SVC            0.953027\n",
       "Decision Tree  0.919624\n",
       "AdaBoost (DT)  0.918580"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame(accuracies, index=[\"AdaBoost (DT)\", \"Decision Tree\", \"SVC\", \"KNN\"], columns=[\"Accuracy\"]).sort_values(\"Accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df4a679",
   "metadata": {},
   "source": [
    "# 4. Explain reasons (10 points)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4256dbe0",
   "metadata": {},
   "source": [
    "All classifiers have the high accuracy more than 90% except Boosting model.\n",
    "\n",
    "We can observe that AdaBoost performs slightly better than the Decision Tree as it combines many Decision Trees\n",
    "\n",
    "I infer that KNN and SVC use hyperplanes to separate the datapoints which leads to more accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ae0409",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
